{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b13903e-2742-434b-a3bd-3b3a61249c8a",
   "metadata": {},
   "source": [
    "# DNBLab Jupyter Notebook Tutorial\n",
    "\n",
    "## Herunterladen freier digitaler Objekte\n",
    "\n",
    "Dieses DNBLab-Tutorial beschreibt beispielhaft, wie freie digitale Objekte der Deutschen Nationalbibliothek mit Hilfe der Metadaten eines Datensets heruntergeladen werden können. \n",
    "\n",
    "Entsprechende Datensets können auf mehreren Wegen zuvor heruntergeladen oder selbst erstellt werden: \n",
    "\n",
    "  - Vorgefertigte Datensets im DNBLab herunterladen: [www.dnb.de/dnblabsets](https://www.dnb.de/dnblabsets)\n",
    "  - Datenset selbst erstellen: [DNB SRU Query Tool](https://github.com/deutsche-nationalbibliothek/SRUQueryTool/releases/tag/v1.0)\n",
    "  - Tutorial zur Erstellung eigener Datensets mit Hilfe der SRU-Schnittstelle der DNB: [DNBLab-Tutorials](https://mybinder.org/v2/gh/deutsche-nationalbibliothek/dnblab/HEAD)\n",
    "  - Tutorial zum Download vorgefertigte Datensets über die OAI-PMH-Schnittstellen der DNB: [DNBLab-Tutorials](https://mybinder.org/v2/gh/deutsche-nationalbibliothek/dnblab/HEAD)\n",
    "  - Kleinere Datensets bis 10.000 Datensätze können zudem über den Datenshop des Portals in verschiedenen Metadatenformaten heruntergeladen werden: [Datenshop](https://portal.dnb.de/metadataShopHome)\n",
    "\n",
    "Um den Download dazugehöriger Objekte mit diesem Tutorial durchzuführen, wählen oder erstellen Sie Ihre Datensets im Metadatenformat **MARC21-xml**. \n",
    "\n",
    "\n",
    "### Inhalt\n",
    "\n",
    "  - Einrichten der Arbeitsumgebung\n",
    "  - Benötigte Informationen aus Datenset zusammenstellen\n",
    "  - Herunterladen der Objekte\n",
    "\n",
    "\n",
    "**Hintergrundinformation** \n",
    "\n",
    "Die freien digitalen Objekte können aus dem Langzeitarchiv der DNB heruntergeladen werden. Der Zugriff auf das Objekt funktioniert hierfür mit Hilfe der jeweiligen IDN (Identifikationsnummer des Datensatzes), die als Teil eines persistenten Links den dauerhaften Zugriff auf das jeweilige Objekt ermöglicht. Im folgenden wird dieser Ansatz vorgestellt. Mehr Informationen zum Objektzugriff über Permalinks gibt es auch in unserem DNBLab-Handout: [XXXXXXXXXXXXXXXXXXXXXXXXXXXX](XXXXXX). \n",
    "\n",
    "Teilweise kann auf die freien digitalen Objekte auch über Links auf andere Repositorien, die sich ebenfalls in den Metadaten befinden, zugegriffen werden. Da hier allerdings große Unterschiede in der Persistenz dieser Links sowie den Zugriffsarten ( bspw. führt der Link direkt aufs Objekt oder erst auf eine Landingpage?) je nach Ablieferer bestehen, eignet sich diese Art des Zugriffs für das Herunterladen einer größerer Anzahl freier Objekte nicht. \n",
    "\n",
    "\n",
    "### Einrichten der Arbeitsumgebung\n",
    "\n",
    "Um die Arbeitsumgebung für die folgenden Schritte passend einzurichten, werden zunächst folgende benötigte Python-Bibliotheken importiert: \n",
    "Für Anfragen über die SRU-Schnittstelle wird Requests (https://docs.python-requests.org/en/latest/) verwendet, zur Verarbeitung der XML-Daten BeautifulSoup https://www.crummy.com/software/BeautifulSoup/ und etree https://docs.python.org/3/library/xml.etree.elementtree.html. Mit Pandas https://pandas.pydata.org/ werden die aus dem MARC21-Format ausgelesenen Elemente weiterverarbeitet. In der Jupyter Notebook Umgebung kann der dokumentierte Code direkt ausgeführt und angepasst werden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e2ba04-7d15-4710-b7dd-ea896fb6f2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import pandas as pd\n",
    "import os\n",
    "import wget\n",
    "import PyPDF2\n",
    "from PyPDF2 import PdfReader\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0117d27-e3f6-4afc-97e0-15b87339e7d2",
   "metadata": {},
   "source": [
    "### Benötigte Informationen aus Datenset zusammenstellen \n",
    "\n",
    "Hierfür muss zunächst das Datenset eingelesen und die benötigten Informationen extrahiert werden. Im vorliegenden Beispiel wird ein Datenset im MARC21-xml-Format verwendet. Für Datensets in anderen Metadatenformaten muss der Code entsprechend geändert werden. Liegt das Datenset bereits als CSV, Excel oder in anderer tabellarischer Form vor, kann dieser Schritt übersprungen werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fdb8b4-15d4-4d2c-a8ea-967465e13650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden einer MARC-xml-Datei in ElementTree - Hier den jeweiligen Dateinamen eingeben! (statt \"testdata.xml\")\n",
    "tree = etree.parse('testdata.xml')\n",
    "\n",
    "root = tree.getroot()                \n",
    "ns = {'marc': 'http://www.loc.gov/MARC21/slim'} \n",
    "records = root.findall('.//marc:record', namespaces=ns)\n",
    "print(\"Gefundene Records:\", len(records))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47584439-72ce-4ecb-b40e-a12f3759d32f",
   "metadata": {},
   "source": [
    "Wurden die Datensätze aus dem Datenset erfolgreich geladen, kann mit Hilfe der folgenden Funktion die jeweilige IDN (Identifikationsnummer des Datensatzes) aus den Metadaten extrahiert und in ein Dataframe überführt werden: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c98073-4229-4958-8e61-4259f2e0c591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Extrahieren von Informationen, angepasst auf die IDN\n",
    "def parse_record(record):\n",
    "    ns = {\"marc\": \"http://www.loc.gov/MARC21/slim\"}\n",
    "    \n",
    "    def extract_text(xpath_query):\n",
    "        fields = record.xpath(xpath_query, namespaces=ns)\n",
    "        if fields:\n",
    "            return \"; \".join(field.text.replace('\\x98', '').replace('\\x9c', '') for field in fields if field.text)\n",
    "        return \"unknown\"\n",
    "\n",
    "    idn = extract_text(\"marc:controlfield[@tag='001']\")\n",
    "\n",
    "    return {\"idn\": idn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2978b485-bd48-45e0-8460-22f9fe9b5d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [parse_record(record) for record in records]\n",
    "df = pd.DataFrame(result)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5670437d-7523-457a-a4de-0d466d2096d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Alternative: Datenset liegt bereits im Tabellenformat vor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da74531a-8589-46f0-9690-5c230663b240",
   "metadata": {},
   "source": [
    "Liegt das Datenset bereits als Tabelle in Form einer CSV- oder Excel-Datei vor, entfallen die oberen Schritte. Stattdessen können die benötigten IDNs direkt aus der Tabelle übernommen werden. Beispielhaft folgt hier der Code für eine CSV-Datei, die eine Spalte \"idn\" enthält:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aad5288-b874-44b0-afc6-c94f49359413",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"metadatenset.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adcf780-1aca-4a73-8633-80aadc889750",
   "metadata": {},
   "source": [
    "#### Erstellen einer Linkliste \n",
    "\n",
    "Nun wird für jede IDN der passende Link aufs Objekt im Langzeitarchiv der DNB zusammengesetzt: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c41d1db-3784-4111-80ef-eecb0e9f84c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "linklist = []\n",
    "\n",
    "for idn in df.idn: \n",
    "    link = \"https://d-nb.info/\" + idn + \"/34\"\n",
    "    linklist.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c46e26-546c-46af-bef4-cc06d12fc7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(linklist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f958ef9-e31c-4b3e-b958-36b89b5c4bfc",
   "metadata": {},
   "source": [
    "### Herunterladen der freien Objekte\n",
    "\n",
    "Für dieses Tutorial wird die Linkliste jetzt noch einmal auf die ersten 10 Einträge gekürzt und diese als `testlist` gespeichert. Sollen später alle Objekte aus allen Links in der Liste heruntergeladen werden, muss entsprechend beim Anstoßen der Funktion `download_text` die passende `linklist` übergeben werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d133ad99-b713-4bea-9ada-2ab5f5ba2111",
   "metadata": {},
   "outputs": [],
   "source": [
    "testlist = linklist[:10]\n",
    "print(testlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f7c8d5-29c0-4210-baf5-5caf3557dce0",
   "metadata": {},
   "source": [
    "Nun wird die Funktion zum Herunterladen der Dateien definiert. Diese erstellt zunächst ein neues Verzeichnis mit Wunschnamen (`save_directory`) für die gesammelten Dateien, lädt diese dann herunter und speichert die Objekte unter Nutzung der IDN als Dateiname: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975bffd0-f668-428d-b189-69aee98afd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def download_text(testlist, save_directory):\n",
    "    # Erstellen des später definierten Speicherverzeichnis, falls es dieses noch nicht gibt\n",
    "    if not os.path.exists(save_directory):\n",
    "        os.makedirs(save_directory)\n",
    "    \n",
    "    for link in testlist: \n",
    "        # IDN ermitteln:\n",
    "        idn = link.split('/')[-2]\n",
    "        # Original-Dateiname und -Endung aus Content-Disposition header ermitteln und als Basis nutzen:\n",
    "        response = requests.head(link)\n",
    "        content_disposition = response.headers.get('Content-Disposition')\n",
    "        if content_disposition:\n",
    "            orig_filename = content_disposition.split('filename=')[-1].strip('\";')\n",
    "\n",
    "            # Dateiname aus IDN und originalem Dateiname zusammensetzen: \n",
    "            file_name = f\"{idn}_{orig_filename}\"\n",
    "            file_path = os.path.join(save_directory, file_name)\n",
    "            print(f\" Starte Download: {file_name}\")\n",
    "            try: \n",
    "                #Datei herunterladen:\n",
    "                wget.download(link, out=file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Fehler beim Herunterladen von {link}: {e}\")\n",
    "\n",
    "        else: \n",
    "            print(f\"Kein Objekt zum Datensatz mit der IDN {idn} gefunden. Lade nächstes Objekt...\") \n",
    "\n",
    "    print(\"Fertig.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be298cf-83cf-415c-8ffa-b1b02fb4d77d",
   "metadata": {},
   "source": [
    "Hier wird nun der Name für das gewünschte Verzeichnis benannt und anschließend die Funktion gestartet und ihr die gewünschte Linkliste übergeben (in diesem Fall die `testlist`): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fdc34b-49fe-41c9-b5e9-99545e4c7ac2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_directory = \"downloads\"\n",
    "\n",
    "download_text(testlist, save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb5c7e0-30cb-463e-830c-999dcd286cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
